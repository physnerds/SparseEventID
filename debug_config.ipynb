{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5725d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f453bb",
   "metadata": {},
   "source": [
    "## This is a code to debug the configuration file that leads to error in IOManager in larcv3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e53d7f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import larcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "781cc550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84dd07dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['merged_beam_0.h5', 'Untitled1.ipynb', 'Untitled.ipynb', 'merged_beam_0.pkl', 'look_hdf5_files.ipynb', 'merged_sample_0.h5', 'voxel_occupancy.ipynb', 'read_pickle.ipynb', 'convert_to_pkl.ipynb', '.ipynb_checkpoints', 'test_torch.ipynb']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"./data/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e852117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecdec5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = \"./data/merged_sample_0.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ec0b637",
   "metadata": {},
   "outputs": [],
   "source": [
    "io = larcv.IOManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "397d0a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#io.add_in_file(f)\n",
    "#io.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f5a6788",
   "metadata": {},
   "outputs": [],
   "source": [
    "io_config = {'filler_name': 'primary', 'filler_cfg': 'tmpsbbj5ext', 'verbosity': 5, 'make_copy': False}\n",
    "data_keys = {'image': 'data', 'label_neut': 'label_neut', 'label_prot': 'label_prot', 'label_cpi': 'label_cpi', 'label_npi': 'label_npi'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b728488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class queue_interface(object):\n",
    "\n",
    "    def __init__(self, verbose=False, random_access_mode=\"random_blocks\", seed=None):\n",
    "        '''init function\n",
    "\n",
    "        Not much to store here, just a dict of dataloaders and the keys to access their data.\n",
    "\n",
    "        Queue loaders are manually triggered IO, not always running, so\n",
    "        '''\n",
    "        object.__init__(self)\n",
    "        self._queueloaders  = {}\n",
    "        self._data_keys     = {}\n",
    "        self._dims          = {}\n",
    "        self._verbose       = verbose\n",
    "        self._random_access = RandomAccess[random_access_mode]\n",
    "        self._minibatch_size = {}\n",
    "\n",
    "        self._queue_prev_entries = {}\n",
    "        self._queue_next_entries = {}\n",
    "        self._count = {}\n",
    "\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "            numpy.random.seed(seed)\n",
    "\n",
    "        self._warning = True\n",
    "\n",
    "        self._writer = None\n",
    "\n",
    "    def no_warnings(self):\n",
    "        self._warning = False\n",
    "\n",
    "    def get_next_batch_indexes(self, mode, minibatch_size):\n",
    "\n",
    "        # Using the random_access parameter, determine which entries to read:\n",
    "\n",
    "        # In this function, we promote the \"next\" to \"prev\".  Do that first:\n",
    "        if mode not in self._queue_next_entries:\n",
    "            self._queue_next_entries[mode] = None\n",
    "        self._queue_prev_entries[mode] = self._queue_next_entries[mode]\n",
    "        # (If this has not been run, they will both be set to None)\n",
    "\n",
    "        if self._random_access == RandomAccess.serial_access:\n",
    "            # Figure out the last batch's highest entry:\n",
    "            if mode in self._queue_prev_entries:\n",
    "                if self._queue_prev_entries[mode] is not None:\n",
    "                    last_entry = numpy.max(self._queue_prev_entries[mode])\n",
    "                else:\n",
    "                    last_entry = -1\n",
    "            else:\n",
    "                last_entry = -1\n",
    "\n",
    "            next_last_entry = minibatch_size + last_entry + 1\n",
    "\n",
    "            n_entries = self._queueloaders[mode].fetch_n_entries()\n",
    "\n",
    "            if next_last_entry < n_entries:\n",
    "                next_entries = numpy.arange(minibatch_size, dtype=numpy.int32) + last_entry + 1\n",
    "            else:\n",
    "                # Create an array to cover the entries till the last one ...\n",
    "                next_entries_a = numpy.arange(n_entries - 1 - last_entry, dtype=numpy.int32) + last_entry + 1\n",
    "                # ... and one array for the leftover entries, starting back from zero\n",
    "                next_entries_b = numpy.arange((last_entry + 1 + minibatch_size) % n_entries, dtype=numpy.int32)\n",
    "                # Finally concatenate the two arrays\n",
    "                next_entries = numpy.concatenate((next_entries_a, next_entries_b))\n",
    "\n",
    "        elif self._random_access == RandomAccess.random_blocks:\n",
    "            # How many entries are there?\n",
    "            n_entries = self._queueloaders[mode].fetch_n_entries()\n",
    "            # The number of available choices is the number of entries - minibatch_size - 1:\n",
    "            n_choices = n_entries - minibatch_size - 1\n",
    "            start_entry = numpy.random.randint(low=0, high=n_choices, size=1)\n",
    "            next_entries = numpy.arange(minibatch_size) + start_entry\n",
    "\n",
    "        else:  # self._random_access == RandomAccess.random_events\n",
    "            # Choose randomly, but require unique indexes:\n",
    "            n_entries = self._queueloaders[mode].fetch_n_entries()\n",
    "            next_entries = random.sample(range(n_entries), minibatch_size)\n",
    "\n",
    "\n",
    "        self._queue_next_entries[mode] = next_entries\n",
    "\n",
    "        return next_entries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660d514d",
   "metadata": {},
   "source": [
    "#### This class is taken from queueloader.py. This python class is called from exec.py from larcv_fetcher.py, prepare_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "598e5f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class larcv_queueio (object):\n",
    "\n",
    "    _instance_m={}\n",
    "\n",
    "    @classmethod\n",
    "    def exist(cls,name):\n",
    "        name = str(name)\n",
    "        return name in cls._instance_m\n",
    "\n",
    "    @classmethod\n",
    "    def instance_by_name(cls,name):\n",
    "        return cls._instance_m[name]\n",
    "\n",
    "    def __init__(self):\n",
    "        self._proc = None\n",
    "        self._name = ''\n",
    "        self._verbose = False\n",
    "        self._read_start_time = None\n",
    "        self._read_end_time = None\n",
    "        self._cfg_file = None\n",
    "        self._storage = {}\n",
    "        self._event_entries = None\n",
    "        self._event_ids = None\n",
    "        self._queues_set = False\n",
    "\n",
    "    def reset(self):\n",
    "        while self.is_reading(): time.sleep(0.01)\n",
    "        if self._proc: self._proc.reset()\n",
    "\n",
    "    def __del__(self):\n",
    "        try:\n",
    "            self.reset()\n",
    "        except AttrbuteError:\n",
    "            pass\n",
    "\n",
    "    def configure(self,cfg, color=0):\n",
    "        # if \"this\" was configured before, reset it\n",
    "        if self._name: self.reset()\n",
    "\n",
    "        # get name\n",
    "        if not cfg['filler_name']:\n",
    "            sys.stderr.write('filler_name is empty!\\n')\n",
    "            raise ValueError\n",
    "\n",
    "        # ensure unique name\n",
    "        if self.__class__.exist(cfg['filler_name']) and not self.__class__.instance_by_name(cfg['filler_name']) == self:\n",
    "            sys.stderr.write('filler_name %s already running!' % cfg['filler_name'])\n",
    "            return\n",
    "        self._name = cfg['filler_name']\n",
    "\n",
    "        # get QueueProcessor config file\n",
    "        self._cfg_file = cfg['filler_cfg']\n",
    "        # if not self._cfg_file or not os.path.isfile(self._cfg_file):\n",
    "        #     sys.stderr.write('filler_cfg file does not exist: %s\\n' % self._cfg_file)\n",
    "        #     raise ValueError\n",
    "\n",
    "        # set verbosity\n",
    "        if 'verbosity' in cfg:\n",
    "            self._verbose = bool(cfg['verbosity'])\n",
    "\n",
    "        # configure thread processor\n",
    "        self._proc = larcv.QueueProcessor(self._name)\n",
    "        \n",
    "        #I am testing here.....AB\n",
    "        #okay Queue processor needs the configuration in the JSON format. _cfg_file is not \n",
    "        # in the JSON format. Need to add an additional layer of conversion.....AB\n",
    "        #self._proc.configure(self._cfg_file, color)\n",
    "        data = {}\n",
    "        try:\n",
    "            file_path = self._cfg_file\n",
    "            with open(file_path, \"r\") as json_file:\n",
    "                data = json.load(json_file)\n",
    "        # Process the JSON data here\n",
    "        except FileNotFoundError:\n",
    "            print(f\"queueloader.py:: The file '{file_path}' was not found.\")\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"queueloader.py:: Error decoding JSON: {e}\")\n",
    "\n",
    "        #self._proc.configure(self._cfg_file, color)\n",
    "        self._proc.configure(data[self._name],color)\n",
    "\n",
    "        # fetch batch filler info\n",
    "        print(\"Batch fillers\",self._proc.batch_fillers())\n",
    "        self._storage = {}\n",
    "        # Making a map between process names and data outputs:\n",
    "        for pid, datatype in zip(self._proc.batch_fillers(), self._proc.batch_types()):\n",
    "            # What's the name from the config?\n",
    "            print(\"pid,datatype\",pid,datatype)\n",
    "            name = self._proc.storage_name(pid)\n",
    "            datatype = larcv.BatchDataTypeName(datatype)\n",
    "            self._storage[name]=batch_pydata(datatype)\n",
    "            if 'make_copy' in cfg and cfg['make_copy']:\n",
    "                self._storage[name]._make_copy = True\n",
    "\n",
    "\n",
    "        # all success?\n",
    "        # register *this* instance\n",
    "        self.__class__._instance_m[self._name] = self\n",
    "\n",
    "\n",
    "    def set_next_batch(self, batch_indexes):\n",
    "        # if type(batch_indexes) != larcv.VectorOfSizet:\n",
    "        #     indexes = larcv.VectorOfSizet()\n",
    "        #     indexes.resize(len(batch_indexes))\n",
    "        #     for i, val in enumerate(batch_indexes):\n",
    "        #         indexes[i] = int(val)\n",
    "        #     batch_indexes = indexes\n",
    "        self._proc.set_next_batch(batch_indexes)\n",
    "\n",
    "    def batch_process(self):\n",
    "        while self.is_reading():\n",
    "            time.sleep(0.01)\n",
    "        self._proc.batch_process()\n",
    "\n",
    "\n",
    "    def prepare_next(self):\n",
    "        self._proc.prepare_next()\n",
    "\n",
    "\n",
    "    def is_reading(self,storage_id=None):\n",
    "\n",
    "        ready =  self._proc.is_next_ready() and not self._proc.is_reading()\n",
    "\n",
    "        # print(f\"Overall ready? {ready}\")\n",
    "        # print(f\"QueueProcessor ready? {self._proc.is_next_ready()}\")\n",
    "\n",
    "        return not ready\n",
    "\n",
    "    def pop_current_data(self):\n",
    "        # Promote the \"next\" data to current in C++ and release current\n",
    "        self._proc.pop_current_data()\n",
    "\n",
    "\n",
    "\n",
    "    def next(self,store_entries=False,store_event_ids=False):\n",
    "\n",
    "        # Calling next will load the next set of data into batch_pydata.  It does not do any\n",
    "        # automatic data loading or steping, you must do this manually.\n",
    "\n",
    "        for name,storage in self._storage.items():\n",
    "            dtype = storage.dtype()\n",
    "            batch_data = self._proc.__getattribute__(f\"get_batch_{dtype}\")(name)\n",
    "\n",
    "            # print(type(batch_storage), \" at \", batch_storage)\n",
    "            # batch_data = batch_storage.get_batch()\n",
    "            # print(type(batch_data), \" at \", batch_data)\n",
    "            storage.set_data(storage_id=name, larcv_batchdata=batch_data)\n",
    "\n",
    "        if not store_entries: self._event_entries = None\n",
    "        else: self._event_entries = self._proc.processed_entries()\n",
    "\n",
    "        if not store_event_ids: self._event_ids = None\n",
    "        else: self._event_ids = self._proc.processed_events()\n",
    "\n",
    "        return\n",
    "\n",
    "    def fetch_data(self,key):\n",
    "        try:\n",
    "            return self._storage[key]\n",
    "        except KeyError:\n",
    "            sys.stderr.write('Cannot fetch data w/ key %s (unknown)\\n' % key)\n",
    "            return\n",
    "\n",
    "    def fetch_event_ids(self):\n",
    "        return self._event_ids\n",
    "\n",
    "    def fetch_entries(self):\n",
    "        return self._event_entries\n",
    "\n",
    "    def fetch_n_entries(self):\n",
    "        return self._proc.get_n_entries()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cf99be",
   "metadata": {},
   "source": [
    "#### This is the duplication of how larcv_queueio is called in larcv_fetcher. If you uncomment the following lines, you will reproduce the error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7b3090c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch fillers []\n",
      "{'filler_name': 'primary', 'filler_cfg': 'tmpsbbj5ext', 'verbosity': 5, 'make_copy': False}\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input>\u001b[00m Opening a file in READ mode: \"/Users/amitbashyal/SparseEventID/data/merged_sample_0.h5\"\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input>\u001b[00m File \"/Users/amitbashyal/SparseEventID/data/merged_sample_0.h5\" has 1404 entries\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<IOManager::initialize>\u001b[00m Prepared input with 1404 entries...\n"
     ]
    }
   ],
   "source": [
    "qio = larcv_queueio()\n",
    "qio.configure(io_config)\n",
    "print(io_config)\n",
    "#print(qio._name)\n",
    "#print(qio.fetch_entries())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f2e3a4",
   "metadata": {},
   "source": [
    "### In fact these two lines pin point the source of errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63246eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids= qio.fetch_event_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "200fec15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ids)\n",
    "entries = qio.fetch_entries()\n",
    "print(entries)\n",
    "qio.next()\n",
    "entries = qio.fetch_entries()\n",
    "print(entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cede46",
   "metadata": {},
   "source": [
    "### The following code is taken from config_builder. This creates a json format config which seems to be expected by the IOManager.cxx in larcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c390abf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This from larcv3/larcv/config_builder.py\n",
    "import larcv\n",
    "import json\n",
    "import uuid\n",
    "\n",
    "class ConfigBuilder:\n",
    "    \"\"\"\n",
    "    Front-end to create configuration objects step by step.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    valid_datatypes = \\\n",
    "        [ f\"tensor{i+1}d\" for i in range(4) ] + \\\n",
    "        [ f\"sparse{i+2}d\" for i in range(2) ] + \\\n",
    "        [ f\"cluster{i+2}d\" for i in range(2) ] + \\\n",
    "        [ f\"bbox{i+2}d\" for i in range(2) ] + \\\n",
    "        [\"particle\"] + \\\n",
    "        [\"PID\"]\n",
    "\n",
    "    valid_preprocess = [\n",
    "        \"Downsample\", \"DenseToSparse\", \"Embed\",\n",
    "        \"SparseToDense\", \"TensorFromCluster\", \"Threshold\",\n",
    "        \"BBoxFromParticle\", \"BBoxFromCluster\"\n",
    "    ]\n",
    "\n",
    "    def __init__(self):\n",
    "        self.config = larcv.QueueProcessor.default_config()\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"\n",
    "        Gets the configuration.\n",
    "        \n",
    "        :returns:   The configuration.\n",
    "        \n",
    "        \"\"\"\n",
    "        return self.config\n",
    "\n",
    "    def set_parameter(self,value,*keys):\n",
    "        \"\"\"\n",
    "        Sets the parameter to value, walking into the config dictionary in the order of keys\n",
    "\n",
    "        :param      value:  The value\n",
    "        :type       value:  { type_description }\n",
    "        :param      keys:   The keys\n",
    "        :type       keys:   list\n",
    "\n",
    "        \"\"\"\n",
    "        dct = self.config\n",
    "        for key in keys[:-1]:\n",
    "               dct = dct[key]\n",
    "        dct[keys[-1]] = value\n",
    "        return\n",
    "\n",
    "    def print_config(self):\n",
    "        \"\"\"\n",
    "        Prints a configuration using json to format it.\n",
    "        \n",
    "        \"\"\"\n",
    "        return json.dumps(self.config, indent=2)\n",
    "\n",
    "    def validate_datatype(self, datatype : str):\n",
    "        \"\"\"\n",
    "        Ensure datatype is viable\n",
    "\n",
    "        :param      datatype:  The datatype\n",
    "        :type       datatype:  str\n",
    "        \"\"\"\n",
    "\n",
    "        if datatype not in self.valid_datatypes:\n",
    "            raise TypeError(f\"Unsupported datatype passed to ConfigBuilder: {datatype}\")\n",
    "\n",
    "    def validate_preprocess(self, preprocess : str):\n",
    "        \"\"\"\n",
    "        Ensure preprocess is viable\n",
    "\n",
    "        :param      preprocess:  The preprocess\n",
    "        :type       preprocess:  str\n",
    "        \"\"\"\n",
    "\n",
    "        if preprocess not in self.valid_preprocess:\n",
    "            raise TypeError(f\"Unsupported preprocess passed to ConfigBuilder: {preprocess}\")\n",
    "\n",
    "\n",
    "    def add_preprocess(self, datatype : str, producer : str, process : str, name : str = \"\", **kwargs):\n",
    "        \"\"\"\n",
    "        Adds a preprocess.\n",
    "\n",
    "        :param      datatype:  The datatype of the input\n",
    "        :type       datatype:  str\n",
    "        :param      producer:  The producer of the input\n",
    "        :type       producer:  str\n",
    "        :param      process:   The process name\n",
    "        :type       process:   str\n",
    "        :param      name:      The name of the process in the config (optional)\n",
    "        :type       name:      str\n",
    "        :param      kwargs:    The keywords arguments to override and parameters in the preprocess\n",
    "        :type       kwargs:    dictionary\n",
    "        \"\"\"\n",
    "\n",
    "        # Validate the datatype:\n",
    "        self.validate_datatype(datatype)\n",
    "\n",
    "        # Next, validate the preprocess:\n",
    "        self.validate_preprocess(process)\n",
    "\n",
    "        # Next, we get the default config for the requested process:\n",
    "        proc_config = larcv.__getattribute__(process).default_config()\n",
    "\n",
    "        # for all of the keyword args, make sure they are in the config:\n",
    "        for kwarg in kwargs:\n",
    "            if kwarg != \"Profile\" and kwarg not in proc_config:\n",
    "                raise Exception(f\"Config Parameter {kwarg} not available for\"\n",
    "                                f\"{process}, available parameters: \"\n",
    "                                f\"{proc_config.keys()}\")\n",
    "\n",
    "            # Override default configs:\n",
    "            proc_config[kwarg] = kwargs[kwarg]\n",
    "\n",
    "        # if the supplied name is empty, autogenerate a name:\n",
    "        if name == \"\":\n",
    "            name = f\"{process}_{producer}_{datatype}_\" + str(uuid.uuid4())[:8]\n",
    "\n",
    "        proc_config[\"Producer\"] = producer\n",
    "        proc_config[\"Product\"]  = datatype\n",
    "\n",
    "        # Finally add this process to the configuration\n",
    "\n",
    "        # Process Type is the 'process'\n",
    "        self.config[\"ProcessDriver\"][\"ProcessType\"].append(process)\n",
    "        self.config[\"ProcessDriver\"][\"ProcessName\"].append(name)\n",
    "\n",
    "        if self.config[\"ProcessDriver\"][\"ProcessList\"] is None:\n",
    "            self.config[\"ProcessDriver\"][\"ProcessList\"] = { name : proc_config }\n",
    "        else:\n",
    "            self.config[\"ProcessDriver\"][\"ProcessList\"].update(\n",
    "                {name : proc_config}\n",
    "            )\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    def select_filler(self, datatype : str):\n",
    "        \"\"\"\n",
    "        Pick the batch filler base on datatype\n",
    "\n",
    "        :param      datatype:   The datatype\n",
    "        :type       datatype:   str\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if datatype == \"tensor2d\": return \"BatchFillerTensor2D\"\n",
    "        elif datatype == \"tensor3d\": return \"BatchFillerTensor3D\"\n",
    "        elif datatype == \"sparse2d\": return \"BatchFillerSparseTensor2D\"\n",
    "        elif datatype == \"sparse3d\": return \"BatchFillerSparseTensor3D\"\n",
    "        elif datatype == \"bbox2d\": return \"BatchFillerBBox2D\"\n",
    "        elif datatype == \"bbox3d\": return \"BatchFillerBBox3D\"\n",
    "        elif datatype == \"PID\": return \"BatchFillerPIDLabel\"\n",
    "        elif datatype == \"particle\": return \"BatchFillerParticle\"\n",
    "        else:\n",
    "            raise Exception(f\"Batch Filler not found for datatype{datatype}\")\n",
    "\n",
    "\n",
    "    def add_batch_filler(self, datatype : str, producer : str, name : str = \"\", **kwargs):\n",
    "        \"\"\"\n",
    "        Adds a preprocess.\n",
    "\n",
    "        :param      datatype:  The datatype to load into memory\n",
    "        :type       datatype:  str\n",
    "        :param      producer:  The producer of the datatype\n",
    "        :type       producer:  str\n",
    "        :param      name:      The name of the process in the config file (optional)\n",
    "        :type       name:      str\n",
    "        :param      kwargs:    Any override arguments to the configuration\n",
    "        :type       kwargs:    dictionary\n",
    "        \"\"\"\n",
    "\n",
    "        # Similar to adding a preprocess, but the process is uniquely ID'd\n",
    "        # by the datatype\n",
    "\n",
    "        # Validate the datatype:\n",
    "        self.validate_datatype(datatype)\n",
    "\n",
    "        # Next, validate the preprocess:\n",
    "        filler = self.select_filler(datatype)\n",
    "\n",
    "        # Next, we get the default config for the requested process:\n",
    "        proc_config = larcv.__getattribute__(filler).default_config()\n",
    "\n",
    "        # for all of the keyword args, make sure they are in the config:\n",
    "        for kwarg in kwargs:\n",
    "            if kwarg != \"Profile\" and kwarg not in proc_config:\n",
    "                raise Exception(f\"Config Parameter {kwarg} not available for\"\n",
    "                                f\"{filler}, available parameters: \"\n",
    "                                f\"{proc_config.keys()}\")\n",
    "\n",
    "            # Override default configs:\n",
    "            proc_config[kwarg] = kwargs[kwarg]\n",
    "\n",
    "        # if the supplied name is empty, autogenerate a name:\n",
    "        if name == \"\":\n",
    "            name = f\"{filler}_{producer}_\" + str(uuid.uuid4())[:8]\n",
    "\n",
    "        proc_config[\"Producer\"] = producer\n",
    "\n",
    "        # Finally add this process to the configuration\n",
    "\n",
    "        # Process Type is the 'process'\n",
    "        self.config[\"ProcessDriver\"][\"ProcessType\"].append(filler)\n",
    "        self.config[\"ProcessDriver\"][\"ProcessName\"].append(name)\n",
    "\n",
    "        if self.config[\"ProcessDriver\"][\"ProcessList\"] is None:\n",
    "            self.config[\"ProcessDriver\"][\"ProcessList\"] = { name : proc_config }\n",
    "        else:\n",
    "            self.config[\"ProcessDriver\"][\"ProcessList\"].update(\n",
    "                {name : proc_config}\n",
    "            )\n",
    "\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8716e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_builder = ConfigBuilder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f996b483",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_builder.print_config()\n",
    "m_config = cfg_builder.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87edb0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'InputFiles': [], 'ProcessDriver': {'EnableFilter': False, 'IOManager': {'IOMode': 0, 'Input': {'InputFiles': [], 'ReadOnlyName': [], 'ReadOnlyType': [], 'UseH5CoreDriver': False}, 'Output': {'Compression': 1, 'OutFileName': '', 'StoreOnlyName': [], 'StoreOnlyType': []}, 'Verbosity': 0}, 'NumEntries': 0, 'ProcessList': None, 'ProcessName': [], 'ProcessType': [], 'RandomAccess': False, 'RandomSeed': 0, 'StartEntry': 0, 'Verbosity': 0}, 'ProcessName': 0, 'Verbosity': 2}\n"
     ]
    }
   ],
   "source": [
    "print(m_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a67d0217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InputFiles\n",
      "ProcessDriver\n",
      "ProcessName\n",
      "Verbosity\n"
     ]
    }
   ],
   "source": [
    "for key in m_config:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b277aa00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EnableFilter': False, 'IOManager': {'IOMode': 0, 'Input': {'InputFiles': [], 'ReadOnlyName': [], 'ReadOnlyType': [], 'UseH5CoreDriver': False}, 'Output': {'Compression': 1, 'OutFileName': '', 'StoreOnlyName': [], 'StoreOnlyType': []}, 'Verbosity': 0}, 'NumEntries': 0, 'ProcessList': None, 'ProcessName': [], 'ProcessType': [], 'RandomAccess': False, 'RandomSeed': 0, 'StartEntry': 0, 'Verbosity': 0}\n"
     ]
    }
   ],
   "source": [
    "print(m_config['ProcessDriver'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dce8fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_config['InputFiles'].append(\"/Users/amitbashyal/SparseEventID/data/merged_sample_0.h5\")\n",
    "#qio.configure(io_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f77d68ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filler_name': 'primary', 'filler_cfg': 'tmpsbbj5ext', 'verbosity': 5, 'make_copy': False}\n"
     ]
    }
   ],
   "source": [
    "print(io_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9296c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "_proc = larcv.QueueProcessor(\"primary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc459794",
   "metadata": {},
   "source": [
    "### The line below shows that QueueProcessor::configure takes the format produced from configbuilder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea10584e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<ProcessDriver::configure::L124>\u001b[00m Configuring IO\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<ProcessDriver::configure::L127>\u001b[00m Retrieving self (ProcessDriver) config\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<ProcessDriver::configure::L130>\u001b[00m Enable Filter is :  0\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<ProcessDriver::configure::L132>\u001b[00m RandomAccess is :  0\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<ProcessDriver::configure::L149>\u001b[00m Start looping process list to instantiate processes\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<ProcessDriver::override_input_file>\u001b[00m ProcessDriver.cxx::L31 Called\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<primary::configure>\u001b[00m Done configuration ...\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<ProcessDriver::process_names>\u001b[00m ProcessDriver.cxx::L54 Called\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<ProcessDriver::initialize>\u001b[00m ProcessDriver.cxx::L185 Called\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<ProcessDriver::initialize::L195>\u001b[00m Initializing IO \n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::initialize>\u001b[00m IOManager.cxx::L143 start\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input>\u001b[00m IOManager.cxx::L423 start\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input::L460>\u001b[00m Start inspecting 1files\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input>\u001b[00m Opening a file in READ mode: \"/Users/amitbashyal/SparseEventID/data/merged_sample_0.h5\"\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input>\u001b[00m File \"/Users/amitbashyal/SparseEventID/data/merged_sample_0.h5\" has 1404 entries\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer>\u001b[00m IOManager.cxx::L315 start\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L320>\u001b[00m Requested to register a producer: duneseg (Group cluster2d_duneseg_group)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L368>\u001b[00m It is a new producer registration (key=0)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input::L562>\u001b[00m Registered: producer=duneseg Key=0\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer>\u001b[00m IOManager.cxx::L315 start\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L320>\u001b[00m Requested to register a producer: segment (Group cluster2d_segment_group)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L368>\u001b[00m It is a new producer registration (key=1)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input::L562>\u001b[00m Registered: producer=segment Key=1\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer>\u001b[00m IOManager.cxx::L315 start\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L320>\u001b[00m Requested to register a producer: segment (Group cluster3d_segment_group)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L368>\u001b[00m It is a new producer registration (key=2)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input::L562>\u001b[00m Registered: producer=segment Key=2\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer>\u001b[00m IOManager.cxx::L315 start\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L320>\u001b[00m Requested to register a producer: all (Group particle_all_group)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L368>\u001b[00m It is a new producer registration (key=3)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input::L562>\u001b[00m Registered: producer=all Key=3\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer>\u001b[00m IOManager.cxx::L315 start\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L320>\u001b[00m Requested to register a producer: cpiID (Group particle_cpiID_group)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L368>\u001b[00m It is a new producer registration (key=4)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input::L562>\u001b[00m Registered: producer=cpiID Key=4\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer>\u001b[00m IOManager.cxx::L315 start\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L320>\u001b[00m Requested to register a producer: duneseg (Group particle_duneseg_group)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L368>\u001b[00m It is a new producer registration (key=5)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input::L562>\u001b[00m Registered: producer=duneseg Key=5\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer>\u001b[00m IOManager.cxx::L315 start\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L320>\u001b[00m Requested to register a producer: neutID (Group particle_neutID_group)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L368>\u001b[00m It is a new producer registration (key=6)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input::L562>\u001b[00m Registered: producer=neutID Key=6\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer>\u001b[00m IOManager.cxx::L315 start\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L320>\u001b[00m Requested to register a producer: neutrino (Group particle_neutrino_group)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L368>\u001b[00m It is a new producer registration (key=7)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input::L562>\u001b[00m Registered: producer=neutrino Key=7\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer>\u001b[00m IOManager.cxx::L315 start\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L320>\u001b[00m Requested to register a producer: npiID (Group particle_npiID_group)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L368>\u001b[00m It is a new producer registration (key=8)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input::L562>\u001b[00m Registered: producer=npiID Key=8\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer>\u001b[00m IOManager.cxx::L315 start\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L320>\u001b[00m Requested to register a producer: protID (Group particle_protID_group)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L368>\u001b[00m It is a new producer registration (key=9)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input::L562>\u001b[00m Registered: producer=protID Key=9\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer>\u001b[00m IOManager.cxx::L315 start\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L320>\u001b[00m Requested to register a producer: segment (Group particle_segment_group)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L368>\u001b[00m It is a new producer registration (key=10)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input::L562>\u001b[00m Registered: producer=segment Key=10\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer>\u001b[00m IOManager.cxx::L315 start\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L320>\u001b[00m Requested to register a producer: dunevoxels (Group sparse2d_dunevoxels_group)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L368>\u001b[00m It is a new producer registration (key=11)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input::L562>\u001b[00m Registered: producer=dunevoxels Key=11\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer>\u001b[00m IOManager.cxx::L315 start\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L320>\u001b[00m Requested to register a producer: dunevoxels (Group sparse3d_dunevoxels_group)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L368>\u001b[00m It is a new producer registration (key=12)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input::L562>\u001b[00m Registered: producer=dunevoxels Key=12\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<IOManager::initialize>\u001b[00m Prepared input with 1404 entries...\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<ProcessDriver::initialize::L227>\u001b[00m Preparing access index vector\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<ProcessDriver::process_names>\u001b[00m ProcessDriver.cxx::L54 Called\n"
     ]
    }
   ],
   "source": [
    "_proc.configure(m_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "631ae5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'InputFiles': ['/Users/amitbashyal/SparseEventID/data/merged_sample_0.h5'], 'ProcessDriver': {'EnableFilter': False, 'IOManager': {'IOMode': 0, 'Input': {'InputFiles': [], 'ReadOnlyName': [], 'ReadOnlyType': [], 'UseH5CoreDriver': False}, 'Output': {'Compression': 1, 'OutFileName': '', 'StoreOnlyName': [], 'StoreOnlyType': []}, 'Verbosity': 0}, 'NumEntries': 0, 'ProcessList': None, 'ProcessName': [], 'ProcessType': [], 'RandomAccess': False, 'RandomSeed': 0, 'StartEntry': 0, 'Verbosity': 0}, 'ProcessName': 0, 'Verbosity': 2}\n"
     ]
    }
   ],
   "source": [
    "print(m_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18e5685e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filler_name': 'primary', 'filler_cfg': 'tmpsbbj5ext', 'verbosity': 5, 'make_copy': False}\n"
     ]
    }
   ],
   "source": [
    "print(io_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5557de19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#qio.configure(io_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f391b6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filler_name': 'primary', 'filler_cfg': 'tmpsbbj5ext', 'verbosity': 5, 'make_copy': False}\n"
     ]
    }
   ],
   "source": [
    "print(io_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "973c2077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'InputFiles': ['/Users/amitbashyal/SparseEventID/data/merged_sample_0.h5'], 'ProcessDriver': {'EnableFilter': False, 'IOManager': {'IOMode': 0, 'Input': {'InputFiles': [], 'ReadOnlyName': [], 'ReadOnlyType': [], 'UseH5CoreDriver': False}, 'Output': {'Compression': 1, 'OutFileName': '', 'StoreOnlyName': [], 'StoreOnlyType': []}, 'Verbosity': 0}, 'NumEntries': 0, 'ProcessList': None, 'ProcessName': [], 'ProcessType': [], 'RandomAccess': False, 'RandomSeed': 0, 'StartEntry': 0, 'Verbosity': 0}, 'ProcessName': 0, 'Verbosity': 2}\n"
     ]
    }
   ],
   "source": [
    "print(m_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92a35d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81800146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mixed_file(filename):\n",
    "    # Read file as a string\n",
    "    with open(filename, 'r') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Convert to a format that's compliant with JSON\n",
    "    content = content.replace(\"{\", \"{\\n\").replace(\"}\", \"\\n}\")\n",
    "    content = content.replace(\":\", \": \").replace(\", \", \",\\n\")\n",
    "    lines = content.split('\\n')\n",
    "    lines = ['\"' + line.split(\":\")[0].strip() + '\":' + line.split(\":\")[1] if ':' in line else line for line in lines]\n",
    "    json_compliant_content = \"\\n\".join(lines)\n",
    "    \n",
    "    # Load the string as JSON\n",
    "    data = json.loads(json_compliant_content)\n",
    "    return data\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#    filename = '/tmp/tmpsbbj5ext'  # Replace with your file path\n",
    "#    data = read_mixed_file(filename)\n",
    "#    print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51312a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"InputFiles\": [\\n    \"/Users/amitbashyal/SparseEventID/data/merged_sample_0.h5\"\\n  ],\\n  \"ProcessDriver\": {\\n    \"EnableFilter\": false,\\n    \"IOManager\": {\\n      \"IOMode\": 0,\\n      \"Input\": {\\n        \"InputFiles\": [],\\n        \"ReadOnlyName\": [],\\n        \"ReadOnlyType\": [],\\n        \"UseH5CoreDriver\": false\\n      },\\n      \"Output\": {\\n        \"Compression\": 1,\\n        \"OutFileName\": \"\",\\n        \"StoreOnlyName\": [],\\n        \"StoreOnlyType\": []\\n      },\\n      \"Verbosity\": 0\\n    },\\n    \"NumEntries\": 0,\\n    \"ProcessList\": null,\\n    \"ProcessName\": [],\\n    \"ProcessType\": [],\\n    \"RandomAccess\": false,\\n    \"RandomSeed\": 0,\\n    \"StartEntry\": 0,\\n    \"Verbosity\": 0\\n  },\\n  \"ProcessName\": 0,\\n  \"Verbosity\": 2\\n}'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_builder.print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82918759",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = larcv.QueueProcessor.default_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4cec3541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'InputFiles': [], 'ProcessDriver': {'EnableFilter': False, 'IOManager': {'IOMode': 0, 'Input': {'InputFiles': [], 'ReadOnlyName': [], 'ReadOnlyType': [], 'UseH5CoreDriver': False}, 'Output': {'Compression': 1, 'OutFileName': '', 'StoreOnlyName': [], 'StoreOnlyType': []}, 'Verbosity': 0}, 'NumEntries': 0, 'ProcessList': None, 'ProcessName': [], 'ProcessType': [], 'RandomAccess': False, 'RandomSeed': 0, 'StartEntry': 0, 'Verbosity': 0}, 'ProcessName': 0, 'Verbosity': 2}\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b622c05",
   "metadata": {},
   "source": [
    "### IO Config Content : \n",
    "{'filler_name': 'primary', 'filler_cfg': '/tmp/tmpsbbj5ext', 'verbosity': 5, 'make_copy': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2678704e",
   "metadata": {},
   "source": [
    "### Config from QueueProcessor.cxx (More info in QueueProcessor::configure(const json&, int )\n",
    "{'InputFiles': [], 'ProcessDriver': {'EnableFilter': False, 'IOManager': {'IOMode': 0, 'Input': {'InputFiles': [], 'ReadOnlyName': [], 'ReadOnlyType': [], 'UseH5CoreDriver': False}, 'Output': {'Compression': 1, 'OutFileName': '', 'StoreOnlyName': [], 'StoreOnlyType': []}, 'Verbosity': 0}, 'NumEntries': 0, 'ProcessList': None, 'ProcessName': [], 'ProcessType': [], 'RandomAccess': False, 'RandomSeed': 0, 'StartEntry': 0, 'Verbosity': 0}, 'ProcessName': 0, 'Verbosity': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ebd0a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/tmp/tmpsbbj5ext'\n",
    "with open(file_path,'r') as f:\n",
    "    file_content = f.read()\n",
    "    \n",
    "json_output = 'out.json'\n",
    "with open(json_output,'w') as json_file:\n",
    "    json.dump(file_content,json_file,indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8ff170b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"primary: {\\n  Verbosity: 5 \\n  EnableFilter: false \\n  NumThreads: 4 \\n  InputFiles: [\\\"/Users/amitbashyal/SparseEventID/data/merged_sample_0.h5\\\"]\\n  NumBatchStorage: 4 \\n  RandomSeed: 0 \\n  RandomAccess: 0 \\n  ProcessType: [\\\"BatchFillerSparseTensor3D\\\",\\\"BatchFillerPIDLabel\\\",\\\"BatchFillerPIDLabel\\\",\\\"BatchFillerPIDLabel\\\",\\\"BatchFillerPIDLabel\\\"]\\n  ProcessName: [\\\"data\\\",\\\"label_neut\\\",\\\"label_prot\\\",\\\"label_cpi\\\",\\\"label_npi\\\"]\\n\\n  ProcessList: {\\n    data: {\\n      Verbosity: 3\\n      TensorProducer: \\\"dunevoxels\\\"\\n      IncludeValues: true\\n      MaxVoxels: 30000\\n      UnfilledVoxelValue: -999\\n      Augment: true\\n    }\\n    label_neut: {\\n      Verbosity: 3\\n      ParticleProducer: neutID\\n      PdgClassList: [0,1,2]\\n    }\\n    label_prot: {\\n      Verbosity: 3\\n      ParticleProducer: protID\\n      PdgClassList: [0,1,2]\\n    }\\n    label_cpi: {\\n      Verbosity: 3\\n      ParticleProducer: cpiID\\n      PdgClassList: [0,1]\\n    }\\n    label_npi: {\\n      Verbosity: 3\\n      ParticleProducer: npiID\\n      PdgClassList: [0,1]\\n    }\\n  }\\n}\\n\"\n"
     ]
    }
   ],
   "source": [
    "with open(json_output,'r') as jfile:\n",
    "    data = json.load(jfile)\n",
    "print(json.dumps(data,indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bdb2800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_proc.configure(json_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14942931",
   "metadata": {},
   "source": [
    "### If everything had worked:\n",
    "\n",
    "[NORMAL]  <primary::configure> Done configuration ...\n",
    "    [NORMAL]  <IOManager::prepare_input> Opening a file in READ mode: \"/Users/amitbashyal/SparseEventID/data/merged_sample_0.h5\"\n",
    "    [NORMAL]  <IOManager::prepare_input> File \"/Users/amitbashyal/SparseEventID/data/merged_sample_0.h5\" has 1404 entries\n",
    "    [NORMAL]  <IOManager::initialize> Prepared input with 1404 entries..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "deaa7724",
   "metadata": {},
   "outputs": [],
   "source": [
    "j_data = json.dumps(data,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "af28e486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/amitbashyal/SparseEventID/data/merged_sample_0.h5']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_config[\"InputFiles\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d1950796",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_json = json.loads(j_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc4a5700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(m_config),type(config_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b15f7fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primary: {\n",
      "  Verbosity: 5 \n",
      "  EnableFilter: false \n",
      "  NumThreads: 4 \n",
      "  InputFiles: [\"/Users/amitbashyal/SparseEventID/data/merged_sample_0.h5\"]\n",
      "  NumBatchStorage: 4 \n",
      "  RandomSeed: 0 \n",
      "  RandomAccess: 0 \n",
      "  ProcessType: [\"BatchFillerSparseTensor3D\",\"BatchFillerPIDLabel\",\"BatchFillerPIDLabel\",\"BatchFillerPIDLabel\",\"BatchFillerPIDLabel\"]\n",
      "  ProcessName: [\"data\",\"label_neut\",\"label_prot\",\"label_cpi\",\"label_npi\"]\n",
      "\n",
      "  ProcessList: {\n",
      "    data: {\n",
      "      Verbosity: 3\n",
      "      TensorProducer: \"dunevoxels\"\n",
      "      IncludeValues: true\n",
      "      MaxVoxels: 30000\n",
      "      UnfilledVoxelValue: -999\n",
      "      Augment: true\n",
      "    }\n",
      "    label_neut: {\n",
      "      Verbosity: 3\n",
      "      ParticleProducer: neutID\n",
      "      PdgClassList: [0,1,2]\n",
      "    }\n",
      "    label_prot: {\n",
      "      Verbosity: 3\n",
      "      ParticleProducer: protID\n",
      "      PdgClassList: [0,1,2]\n",
      "    }\n",
      "    label_cpi: {\n",
      "      Verbosity: 3\n",
      "      ParticleProducer: cpiID\n",
      "      PdgClassList: [0,1]\n",
      "    }\n",
      "    label_npi: {\n",
      "      Verbosity: 3\n",
      "      ParticleProducer: npiID\n",
      "      PdgClassList: [0,1]\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = '/tmp/tmpsbbj5ext'\n",
    "with open(file_path,'r') as f:\n",
    "    file_content = f.read()\n",
    "    #data = json.load(f)\n",
    "    print(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "285af3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"InputFiles\": [\n",
      "        \"/Users/amitbashyal/SparseEventID/data/merged_sample_0.h5\"\n",
      "    ],\n",
      "    \"ProcessDriver\": {\n",
      "        \"EnableFilter\": false,\n",
      "        \"IOManager\": {\n",
      "            \"IOMode\": 0,\n",
      "            \"Input\": {\n",
      "                \"InputFiles\": [],\n",
      "                \"ReadOnlyName\": [],\n",
      "                \"ReadOnlyType\": [],\n",
      "                \"UseH5CoreDriver\": false\n",
      "            },\n",
      "            \"Output\": {\n",
      "                \"Compression\": 1,\n",
      "                \"OutFileName\": \"\",\n",
      "                \"StoreOnlyName\": [],\n",
      "                \"StoreOnlyType\": []\n",
      "            },\n",
      "            \"Verbosity\": 0\n",
      "        },\n",
      "        \"NumEntries\": 0,\n",
      "        \"ProcessList\": null,\n",
      "        \"ProcessName\": [],\n",
      "        \"ProcessType\": [],\n",
      "        \"RandomAccess\": false,\n",
      "        \"RandomSeed\": 0,\n",
      "        \"StartEntry\": 0,\n",
      "        \"Verbosity\": 0\n",
      "    },\n",
      "    \"ProcessName\": 0,\n",
      "    \"Verbosity\": 2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(m_config,indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e67060e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = \"tmpsbbj5ext\"\n",
    "\n",
    "try:\n",
    "    with open(file_path, \"r\") as json_file:\n",
    "        data = json.load(json_file)\n",
    "    # Process the JSON data here\n",
    "except FileNotFoundError:\n",
    "    print(f\"The file '{file_path}' was not found.\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error decoding JSON: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7c23bc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_proc.configure(data[\"primary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4ea8eaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Verbosity': 5, 'EnableFilter': False, 'NumThreads': 4, 'InputFiles': ['/Users/amitbashyal/SparseEventID/data/merged_sample_0.h5'], 'NumBatchStorage': 4, 'RandomSeed': 0, 'RandomAccess': 0, 'ProcessType': ['BatchFillerSparseTensor3D', 'BatchFillerPIDLabel', 'BatchFillerPIDLabel', 'BatchFillerPIDLabel', 'BatchFillerPIDLabel'], 'ProcessName': ['data', 'label_neut', 'label_prot', 'label_cpi', 'label_npi'], 'ProcessList': {'data': {'Verbosity': 3, 'TensorProducer': 'dunevoxels', 'IncludeValues': True, 'MaxVoxels': 30000, 'UnfilledVoxelValue': -999, 'Augment': True}, 'label_neut': {'Verbosity': 3, 'ParticleProducer': 'neutID', 'PdgClassList': [0, 1, 2]}, 'label_prot': {'Verbosity': 3, 'ParticleProducer': 'protID', 'PdgClassList': [0, 1, 2]}, 'label_cpi': {'Verbosity': 3, 'ParticleProducer': 'cpiID', 'PdgClassList': [0, 1]}, 'label_npi': {'Verbosity': 3, 'ParticleProducer': 'npiID', 'PdgClassList': [0, 1]}}}\n"
     ]
    }
   ],
   "source": [
    "print(data[\"primary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "07123687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<ProcessDriver::reset>\u001b[00m ProcessDriver.cxx::L19 Called\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::reset>\u001b[00m IOManager.cxx::L1102 start\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<ProcessDriver::reset>\u001b[00m ProcessDriver.cxx::L19 Called\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::reset>\u001b[00m IOManager.cxx::L1102 start\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<ProcessDriver::reset>\u001b[00m ProcessDriver.cxx::L19 Called\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::reset>\u001b[00m IOManager.cxx::L1102 start\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<ProcessDriver::configure::L124>\u001b[00m Configuring IO\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<ProcessDriver::configure::L127>\u001b[00m Retrieving self (ProcessDriver) config\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<ProcessDriver::configure::L130>\u001b[00m Enable Filter is :  0\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<ProcessDriver::configure::L132>\u001b[00m RandomAccess is :  0\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<ProcessDriver::configure::L149>\u001b[00m Start looping process list to instantiate processes\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<ProcessDriver::override_input_file>\u001b[00m ProcessDriver.cxx::L31 Called\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<ProcessDriver::process_names>\u001b[00m ProcessDriver.cxx::L54 Called\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<ProcessDriver::initialize>\u001b[00m ProcessDriver.cxx::L185 Called\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<ProcessDriver::initialize::L195>\u001b[00m Initializing IO \n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::initialize>\u001b[00m IOManager.cxx::L143 start\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input>\u001b[00m IOManager.cxx::L423 start\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input::L460>\u001b[00m Start inspecting 1files\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input>\u001b[00m Opening a file in READ mode: \"/Users/amitbashyal/SparseEventID/data/merged_sample_0.h5\"\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input>\u001b[00m File \"/Users/amitbashyal/SparseEventID/data/merged_sample_0.h5\" has 1404 entries\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer>\u001b[00m IOManager.cxx::L315 start\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L320>\u001b[00m Requested to register a producer: duneseg (Group cluster2d_duneseg_group)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L368>\u001b[00m It is a new producer registration (key=0)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input::L562>\u001b[00m Registered: producer=duneseg Key=0\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer>\u001b[00m IOManager.cxx::L315 start\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L320>\u001b[00m Requested to register a producer: segment (Group cluster2d_segment_group)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L368>\u001b[00m It is a new producer registration (key=1)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input::L562>\u001b[00m Registered: producer=segment Key=1\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer>\u001b[00m IOManager.cxx::L315 start\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L320>\u001b[00m Requested to register a producer: segment (Group cluster3d_segment_group)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L368>\u001b[00m It is a new producer registration (key=2)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input::L562>\u001b[00m Registered: producer=segment Key=2\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer>\u001b[00m IOManager.cxx::L315 start\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L320>\u001b[00m Requested to register a producer: all (Group particle_all_group)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L368>\u001b[00m It is a new producer registration (key=3)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input::L562>\u001b[00m Registered: producer=all Key=3\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer>\u001b[00m IOManager.cxx::L315 start\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L320>\u001b[00m Requested to register a producer: cpiID (Group particle_cpiID_group)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L368>\u001b[00m It is a new producer registration (key=4)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input::L562>\u001b[00m Registered: producer=cpiID Key=4\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer>\u001b[00m IOManager.cxx::L315 start\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L320>\u001b[00m Requested to register a producer: duneseg (Group particle_duneseg_group)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L368>\u001b[00m It is a new producer registration (key=5)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input::L562>\u001b[00m Registered: producer=duneseg Key=5\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer>\u001b[00m IOManager.cxx::L315 start\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L320>\u001b[00m Requested to register a producer: neutID (Group particle_neutID_group)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L368>\u001b[00m It is a new producer registration (key=6)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input::L562>\u001b[00m Registered: producer=neutID Key=6\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer>\u001b[00m IOManager.cxx::L315 start\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L320>\u001b[00m Requested to register a producer: neutrino (Group particle_neutrino_group)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L368>\u001b[00m It is a new producer registration (key=7)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input::L562>\u001b[00m Registered: producer=neutrino Key=7\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer>\u001b[00m IOManager.cxx::L315 start\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L320>\u001b[00m Requested to register a producer: npiID (Group particle_npiID_group)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L368>\u001b[00m It is a new producer registration (key=8)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input::L562>\u001b[00m Registered: producer=npiID Key=8\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer>\u001b[00m IOManager.cxx::L315 start\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L320>\u001b[00m Requested to register a producer: protID (Group particle_protID_group)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L368>\u001b[00m It is a new producer registration (key=9)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input::L562>\u001b[00m Registered: producer=protID Key=9\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer>\u001b[00m IOManager.cxx::L315 start\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L320>\u001b[00m Requested to register a producer: segment (Group particle_segment_group)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L368>\u001b[00m It is a new producer registration (key=10)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input::L562>\u001b[00m Registered: producer=segment Key=10\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer>\u001b[00m IOManager.cxx::L315 start\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L320>\u001b[00m Requested to register a producer: dunevoxels (Group sparse2d_dunevoxels_group)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L368>\u001b[00m It is a new producer registration (key=11)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input::L562>\u001b[00m Registered: producer=dunevoxels Key=11\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer>\u001b[00m IOManager.cxx::L315 start\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L320>\u001b[00m Requested to register a producer: dunevoxels (Group sparse3d_dunevoxels_group)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::register_producer::L368>\u001b[00m It is a new producer registration (key=12)\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<IOManager::prepare_input::L562>\u001b[00m Registered: producer=dunevoxels Key=12\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<IOManager::initialize>\u001b[00m Prepared input with 1404 entries...\n",
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<ProcessDriver::initialize::L227>\u001b[00m Preparing access index vector\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<ProcessDriver::process_names>\u001b[00m ProcessDriver.cxx::L54 Called\n"
     ]
    }
   ],
   "source": [
    "_proc.configure(data[\"primary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "995ab0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_proc.prepare_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09efab84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
